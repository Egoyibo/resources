Web Scraping
===============================

## Intro
Web Scraping is some crazy shit that allows you can use for many reasons.  A good way to use it is to create your own version of an API, or if a site/serice doesn't supply a good enough API of their own.  

## <a name='toc'>Table of Contents</a>

  1. [Resources](#resources)
  2. [Parsers](#parsers)


### [[⬆]](#toc) <a name='Scraping Libraries'>Scraping Libraries:</a>
1. Python
    1. [Urllib](https://docs.python.org/2/library/urllib.html) | This is a stdlib option and definitely not suggested!
    2. [Requests](http://docs.python-requests.org/en/latest/) | By far the best option available.
    3. [Scrapy](http://scrapy.org/)
2. Node.js (Javascript)
    1. [Requestjs](https://github.com/mikeal/request)
3. Ruby
4. Java


## The Break Down
### [[⬆]](#toc) <a name='Parsers'>Parsers:</a>
1. Python
    1. [BeautifulSoup](http://beautiful-soup-4.readthedocs.org/en/latest/) | Community accepted best Python tool for parsing HTML/XML
2. Node.js (JavaScript)
    1. [Cheerio](https://github.com/cheeriojs/cheerio) | Server sided jQuery tool that allows you to manipulate scraped pages with jQuery like features (has other uses too!)
3. Ruby
4. Java
